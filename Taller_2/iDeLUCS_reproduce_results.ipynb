{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## iDeLUCS usage Example\n",
        "In this notebook I will try to reproduce the results in the iDeLUCS paper with the updated versions of Pyton, Pytorch and CUDA. Using the balanced Fungi dataset as an example.\n"
      ],
      "metadata": {
        "id": "IVNxvQ5zbXII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Kari-Genomics-Lab/iDeLUCS.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD_8U8ncbWoi",
        "outputId": "da5978dc-afdc-4818-de7b-362129d797fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iDeLUCS'...\n",
            "remote: Enumerating objects: 785, done.\u001b[K\n",
            "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 785 (delta 179), reused 243 (delta 143), pack-reused 474\u001b[K\n",
            "Receiving objects: 100% (785/785), 139.32 MiB | 17.35 MiB/s, done.\n",
            "Resolving deltas: 100% (408/408), done.\n",
            "Updating files: 100% (172/172), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd iDeLUCS/ && python setup.py build_ext --inplace && pip install -e .\n",
        "\n",
        "#Colab will only give you 2 cores\n",
        "!sed -i 's/torch.set_num_threads(cpu_count() - 2 )/torch.set_num_threads(cpu_count())/g' iDeLUCS/idelucs/__main__.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp7iW_dApMOz",
        "outputId": "dff310d1-8dc8-4bdf-e3d6-53684e708222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/setuptools/config/pyprojecttoml.py:66: _BetaConfiguration: Support for `[tool.setuptools]` in `pyproject.toml` is still *beta*.\n",
            "  config = read_configuration(filepath, True, ignore_option_errors, dist)\n",
            "running build_ext\n",
            "Compiling idelucs/kmers.pyx because it changed.\n",
            "[1/1] Cythonizing idelucs/kmers.pyx\n",
            "building 'idelucs.kmers' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/idelucs\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.10 -c idelucs/kmers.c -o build/temp.linux-x86_64-cpython-310/idelucs/kmers.o\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/idelucs\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/idelucs/kmers.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/idelucs/kmers.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/idelucs/kmers.cpython-310-x86_64-linux-gnu.so -> idelucs\n",
            "Obtaining file:///content/iDeLUCS\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.24.2 (from idelucs==0.1.7)\n",
            "  Using cached numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting torch==2.0 (from idelucs==0.1.7)\n",
            "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from idelucs==0.1.7) (3.0.9)\n",
            "Collecting matplotlib==3.7 (from idelucs==0.1.7)\n",
            "  Using cached matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting pandas==2.0.0 (from idelucs==0.1.7)\n",
            "  Using cached pandas-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "Collecting scikit-learn==1.2.1 (from idelucs==0.1.7)\n",
            "  Using cached scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Collecting scipy==1.10.1 (from idelucs==0.1.7)\n",
            "  Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "Collecting umap-learn==0.5.3 (from idelucs==0.1.7)\n",
            "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
            "Collecting hdbscan==0.8.32 (from idelucs==0.1.7)\n",
            "  Using cached hdbscan-0.8.32-cp310-cp310-linux_x86_64.whl\n",
            "Collecting cython (from idelucs==0.1.7)\n",
            "  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan==0.8.32->idelucs==0.1.7) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7->idelucs==0.1.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0->idelucs==0.1.7) (2023.4)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.0->idelucs==0.1.7)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.1->idelucs==0.1.7) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0->idelucs==0.1.7) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0->idelucs==0.1.7) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0->idelucs==0.1.7) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0->idelucs==0.1.7) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0->idelucs==0.1.7) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0->idelucs==0.1.7)\n",
            "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3->idelucs==0.1.7) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn==0.5.3->idelucs==0.1.7)\n",
            "  Using cached pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3->idelucs==0.1.7) (4.66.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0->idelucs==0.1.7) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0->idelucs==0.1.7) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0->idelucs==0.1.7) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0->idelucs==0.1.7)\n",
            "  Using cached lit-18.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn==0.5.3->idelucs==0.1.7) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7->idelucs==0.1.7) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0->idelucs==0.1.7) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0->idelucs==0.1.7) (1.3.0)\n",
            "Building wheels for collected packages: idelucs\n",
            "  Building editable for idelucs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idelucs: filename=idelucs-0.1.7-0.editable-cp310-cp310-linux_x86_64.whl size=3761 sha256=72dc9f4c67f70e155571726599354a77d5c66c37c565108734290b44b7cde41d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b8jaa31t/wheels/46/9f/29/82a3159114d74900b64a251c671aa1ff5c3e1b2f2522fb6054\n",
            "Successfully built idelucs\n",
            "Installing collected packages: lit, tzdata, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, cython, scipy, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, scikit-learn, matplotlib, pynndescent, hdbscan, umap-learn, triton, torch, idelucs\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.9\n",
            "    Uninstalling Cython-3.0.9:\n",
            "      Successfully uninstalled Cython-3.0.9\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.26.0 requires matplotlib>=3.7.1, but you have matplotlib 3.7.0 which is incompatible.\n",
            "bigframes 0.26.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cython-0.29.37 hdbscan-0.8.32 idelucs-0.1.7 lit-18.1.2 matplotlib-3.7.0 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-2.0.0 pynndescent-0.5.11 scikit-learn-1.2.1 scipy-1.10.1 torch-2.0.0 triton-2.0.0 tzdata-2024.1 umap-learn-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!idelucs -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgttOBusdC3r",
        "outputId": "5067298b-73f4-4b64-f9f8-91393b04ea02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: idelucs [-h] [--sequence_file SEQUENCE_FILE] [--n_clusters N_CLUSTERS]\n",
            "               [--n_epochs N_EPOCHS] [--n_mimics N_MIMICS] [--batch_sz BATCH_SZ]\n",
            "               [--GT_file GT_FILE] [--k K] [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "               [--weight WEIGHT] [--lambda LAMBDA] [--lr LR] [--n_voters N_VOTERS]\n",
            "               [--model_size MODEL_SIZE] [--plot PLOT]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --sequence_file SEQUENCE_FILE\n",
            "  --n_clusters N_CLUSTERS\n",
            "                        Expected or maximum number of clusters to find. It should be equal or\n",
            "                        greater than n_true_clusters when GT is provided. NOTE: Use 0 for\n",
            "                        automatically finding fine-grained clusters\n",
            "  --n_epochs N_EPOCHS   Number of training epochs. An epoch is defined as a training iteration\n",
            "                        over all the training pairs.\n",
            "  --n_mimics N_MIMICS   Number of data augmentations per sequence that will be considered during\n",
            "                        training.\n",
            "  --batch_sz BATCH_SZ\n",
            "  --GT_file GT_FILE\n",
            "  --k K                 k-mer length\n",
            "  --optimizer OPTIMIZER\n",
            "  --scheduler SCHEDULER\n",
            "  --weight WEIGHT       Relative importance of the contrastive objective on the final loss. Use a\n",
            "                        higher value when low intra- cluster distance is expected and a lower\n",
            "                        value when high intra-cluster variability is expected\n",
            "  --lambda LAMBDA       Hyperparameter to control cluster balance. Use lambda: 1.2 when unbalanced\n",
            "                        clusters are expected Use lambda: 2.8 when perfectly balanced clusters are\n",
            "                        expected\n",
            "  --lr LR               Learning Rate\n",
            "  --n_voters N_VOTERS   Number of Voters\n",
            "  --model_size MODEL_SIZE\n",
            "                        Selection of 'conv', 'small', 'linear' or 'full'\n",
            "  --plot PLOT           Set to True to plot the final output representation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip iDeLUCS/data/Protists.zip\n",
        "!rm iDeLUCS/data/Protists.zip\n",
        "!unzip iDeLUCS/data/Insects.zip\n",
        "!rm iDeLUCS/data/Insects.zip\n",
        "!unzip iDeLUCS/data/Fungi.zip\n",
        "!rm iDeLUCS/data/Fungi.zip\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD9gdPFGvtlI",
        "outputId": "11f190e8-f585-4e8d-adfb-a28f3e9d857d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  iDeLUCS/data/Protists.zip\n",
            "  inflating: Protists.fas            \n",
            "  inflating: balanced_Protists.fas   \n",
            "  inflating: Protists_GT.tsv         \n",
            "  inflating: balanced_Protists_GT.tsv  \n",
            "Archive:  iDeLUCS/data/Insects.zip\n",
            "  inflating: mtInsects.fas           \n",
            "  inflating: balanced_mtInsects.fas  \n",
            "  inflating: mtInsects_GT.tsv        \n",
            "  inflating: balanced_mtInsects_GT.tsv  \n",
            "Archive:  iDeLUCS/data/Fungi.zip\n",
            "  inflating: Fungi.fas               \n",
            "  inflating: balanced_Fungi.fas      \n",
            "  inflating: Fungi_GT.tsv            \n",
            "  inflating: balanced_Fungi_GT.tsv   \n",
            "balanced_Fungi.fas\tbalanced_mtInsects_GT.tsv  Fungi.fas\t mtInsects.fas\t   Protists_GT.tsv\n",
            "balanced_Fungi_GT.tsv\tbalanced_Protists.fas\t   Fungi_GT.tsv  mtInsects_GT.tsv  sample_data\n",
            "balanced_mtInsects.fas\tbalanced_Protists_GT.tsv   iDeLUCS\t Protists.fas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!idelucs --sequence_file=balanced_mtInsects.fas --GT_file=balanced_mtInsects_GT.tsv --n_clusters=7 --n_epochs=35 --batch_sz=256 --weight=0.25"
      ],
      "metadata": {
        "id": "zM5Y7oWBkw7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eabe2d4-424a-417a-9332-ae0f1b8c090c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Parameters:\n",
            "sequence_file \t -> balanced_mtInsects.fas\n",
            "n_clusters \t -> 7\n",
            "n_epochs \t -> 35\n",
            "n_mimics \t -> 3\n",
            "batch_sz \t -> 256\n",
            "GT_file \t -> balanced_mtInsects_GT.tsv\n",
            "k \t -> 6\n",
            "optimizer \t -> RMSprop\n",
            "scheduler \t -> None\n",
            "weight \t -> 0.25\n",
            "lambda \t -> 2.8\n",
            "lr \t -> 0.001\n",
            "n_voters \t -> 5\n",
            "model_size \t -> linear\n",
            "plot \t -> False\n",
            "{'Lepidoptera': 650, 'Hemiptera': 650, 'Diptera': 650, 'Coleoptera': 650, 'Dictyoptera': 650, 'Orthoptera': 650, 'Hymenoptera': 650}\n",
            "No. Sequences: \t 4,550\n",
            "Min. Length: \t 14,602\n",
            "Max. Length: \t 25,011\n",
            "Avg. Length: \t 15,897.28\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (1/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (2/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (3/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (4/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (5/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Computing Results ................ACC: 0.9268131868131868\n",
            "........ Saving Results ..............\n",
            "training took: 0:37:7 (hh:mm:ss) and 3.064252 (GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!idelucs --sequence_file=balanced_Fungi.fas --GT_file=balanced_Fungi_GT.tsv --n_clusters=3 --n_epochs=35 --batch_sz=256 --weight=0.25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NioxJYeMXR",
        "outputId": "79bb48ff-e8bf-4590-eb8c-25235f7d13cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Parameters:\n",
            "sequence_file \t -> balanced_Fungi.fas\n",
            "n_clusters \t -> 3\n",
            "n_epochs \t -> 35\n",
            "n_mimics \t -> 3\n",
            "batch_sz \t -> 256\n",
            "GT_file \t -> balanced_Fungi_GT.tsv\n",
            "k \t -> 6\n",
            "optimizer \t -> RMSprop\n",
            "scheduler \t -> None\n",
            "weight \t -> 0.25\n",
            "lambda \t -> 2.8\n",
            "lr \t -> 0.001\n",
            "n_voters \t -> 5\n",
            "model_size \t -> linear\n",
            "plot \t -> False\n",
            "{'Pezizomycotina': 335, 'Saccharomycotina': 335, 'Basidiomycota': 335}\n",
            "No. Sequences: \t 1,005\n",
            "Min. Length: \t 21,684\n",
            "Max. Length: \t 99,976\n",
            "Avg. Length: \t 60,656.88\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (1/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (2/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (3/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (4/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (5/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Computing Results ................ACC: 0.8965174129353234\n",
            "........ Saving Results ..............\n",
            "training took: 0:9:6 (hh:mm:ss) and 1.036436 (GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!idelucs --sequence_file=balanced_Protists.fas --GT_file=balanced_Protists_GT.tsv --n_clusters=3 --n_epochs=35 --batch_sz=256 --weight=0.25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgPWw_ROKe-",
        "outputId": "e4b0f029-efb0-4963-a72f-5c6323220e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Parameters:\n",
            "sequence_file \t -> balanced_Protists.fas\n",
            "n_clusters \t -> 3\n",
            "n_epochs \t -> 35\n",
            "n_mimics \t -> 3\n",
            "batch_sz \t -> 256\n",
            "GT_file \t -> balanced_Protists_GT.tsv\n",
            "k \t -> 6\n",
            "optimizer \t -> RMSprop\n",
            "scheduler \t -> None\n",
            "weight \t -> 0.25\n",
            "lambda \t -> 2.8\n",
            "lr \t -> 0.001\n",
            "n_voters \t -> 5\n",
            "model_size \t -> linear\n",
            "plot \t -> False\n",
            "{'Alveolata': 315, 'Stramenopiles': 315, 'Rhodophyta': 315}\n",
            "No. Sequences: \t 945\n",
            "Min. Length: \t 5,498\n",
            "Max. Length: \t 69,503\n",
            "Avg. Length: \t 24,696.67\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (1/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (2/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (3/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (4/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Training Model (5/5)................/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "........... Computing Results ................ACC: 0.798941798941799\n",
            "........ Saving Results ..............\n",
            "training took: 0:8:31 (hh:mm:ss) and 0.99732 (GB)\n"
          ]
        }
      ]
    }
  ]
}